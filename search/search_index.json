{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#optialgo-and-scikit-learn","title":"<code>optialgo</code> and <code>scikit-learn</code>","text":"<p>If you are used to modeling with <code>scikit-learn</code>, congratulations \ud83e\udd29 you will find optialgo easy to use!</p>"},{"location":"#main-features","title":"Main Features","text":"<pre><code>1. Data Prepration\n2. Data Preprocessing\n3. Text Preprocessing (2x Faster)\n3. Comparing Model\n4. Set Model\n5. Prediction\n6. HyperParameter Tuning\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<p>Before installing OptiAlgo, it is recommended to create an environment first.</p> <p><pre><code>pip install optialgo\n</code></pre> atau</p> <pre><code>pip install git+https://github.com/nsandarma/OptiAlgo.git\n</code></pre> <p>and for text preprocessing needs</p> <pre><code>&gt;&gt;&gt; import nltk\n&gt;&gt;&gt; nltk.download('all')\n</code></pre>"},{"location":"#overview","title":"Overview","text":"<pre><code>import pandas as pd\nfrom optialgo import Dataset, Classification\n\ndf = pd.read_csv('dataset_ex/drug200.csv')\nfeatures = ['Age','Sex','BP','Cholesterol',\"Na_to_K\"]\ntarget = 'Drug'\n\ndataset = Dataset(dataframe=df)\ndataset.fit(features=features,target=target)\n\nclf = Classification()\nresult = clf.compare_model(output='table',train_val=True)\nprint(result)\n</code></pre>"},{"location":"abc/","title":"Abstract Class","text":""},{"location":"abc/#optialgo.Parent","title":"Parent","text":"<pre><code>Parent(dataset: Dataset, algorithm: str = None)\n</code></pre> <p>               Bases: <code>ABC</code></p>"},{"location":"abc/#optialgo.Parent.find_best_params","title":"find_best_params","text":"<pre><code>find_best_params(param_grid: dict, inplace=False)\n</code></pre> <p>Perform hyperparameter tuning to find the best parameters for the model.</p> <p>This method uses grid search cross-validation to find the best parameters for the model stored in the <code>self.model</code> attribute. It takes a dictionary of parameter values to search over and returns the best score and parameters found. Optionally, it can set the best parameters to the model in place.</p> <p>Parameters:</p> <ul> <li> <code>param_grid</code>           \u2013            <p>A dictionary where the keys are parameter names and the values are lists of parameter settings to try. This dictionary is used for performing grid search.</p> </li> <li> <code>inplace</code>           \u2013            <p>If True, the best parameters found by grid search will be set to the model in place. Default is False.</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>tuple or None: If <code>inplace</code> is False, returns a tuple containing the best score and the best parameters found by grid search. If <code>inplace</code> is True, the method sets the best parameters to the model and returns None.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the <code>self.model</code> attribute is not found.</p> </li> </ul> <p>Examples: <pre><code>reg = Regression(dataset, algorithm='linear_regression') # or Classification\nparam_grid = {'alpha': [0.1, 0.01, 0.001], 'max_iter': [100, 1000, 10000]}\nbest_score, best_params = reg.find_best_params(param_grid)\nprint(\"Best Score:\", best_score)\nprint(\"Best Parameters:\", best_params)\n</code></pre></p>"},{"location":"abc/#optialgo.Parent.predict","title":"predict","text":"<pre><code>predict(X_test: ndarray, transform: bool = True)\n</code></pre> <p>Predict for the given test data.</p> <p>Parameters:</p> <ul> <li> <code>X_test</code>           \u2013            <p>The test data to predict labels for.</p> </li> <li> <code>transform</code>           \u2013            <p>Whether to transform the test data using <code>flow_from_array</code> method before prediction (default is True).</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>The predicted for the test data.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the model is not found.</p> </li> </ul>"},{"location":"abc/#optialgo.Parent.save","title":"save","text":"<pre><code>save()\n</code></pre> <p>Serialize and save the model object using pickle.</p> <p>Returns:</p> <ul> <li> <code>bytes</code>          \u2013            <p>Serialized representation of the optialgo object.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>PickleError</code>             \u2013            <p>If serialization fails.</p> </li> </ul>"},{"location":"abc/#optialgo.Parent.set_params","title":"set_params","text":"<pre><code>set_params(params: dict) -&gt; None\n</code></pre> <p>Set parameters for the model.</p> <p>This method updates the parameters of the model stored in the <code>self.model</code> attribute. It uses the provided dictionary of parameters to set new values for the model's parameters.</p> <p>Parameters:</p> <ul> <li> <code>params</code>           \u2013            <p>A dictionary containing the parameter names and values to be set for the model. The keys should be the names of the parameters, and the values should be the desired values for those parameters.</p> </li> </ul> <p>Examples: <pre><code>reg = Regession(dataset, algorithm='linear_regression')\nnew_params = {'alpha': 0.1, 'max_iter': 1000}\nreg.set_params(new_params)\nprint(reg.model[1].get_params())\n# output : {'alpha': 0.1, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'normalize': 'deprecated', ...}\n</code></pre></p>"},{"location":"classification/","title":"Classification","text":""},{"location":"classification/#optialgo.Classification","title":"Classification","text":"<pre><code>Classification(\n    dataset: Dataset,\n    algorithm: Optional[\n        Literal[\n            \"Naive Bayes\",\n            \"K-Nearest Neighbor\",\n            \"SVM\",\n            \"Logistic Regression\",\n            \"Random Forest\",\n            \"Decision Tree\",\n            \"XGBoost\",\n            \"Gradient Boosting\",\n        ]\n    ] = None,\n)\n</code></pre> <p>               Bases: <code>Parent</code></p> <p>If the dataset represents a binary classification problem, it adds the AUC metric to the classification metrics.</p> <p>Parameters:</p> <ul> <li> <code>dataset</code>           \u2013            <p>An instance of the Dataset class, which includes the data and its characteristics.</p> </li> <li> <code>algorithm</code>           \u2013            <p>The algorithm to be used for classification. Default is None.</p> </li> </ul> <p>Examples: <pre><code>dataset = Dataset(dataframe, norm=True, test_size=0.3, seed=123)\ndataset.fit(features=features,target=target)\nclassifier = Classifier(dataset, algorithm='random_forest')\n</code></pre></p>"},{"location":"classification/#optialgo.Classification.compare_model","title":"compare_model","text":"<pre><code>compare_model(\n    output: Literal[\n        \"dict\", \"dataframe\", \"table\", \"only_score\"\n    ] = \"dict\",\n    train_val: bool = True,\n    n_splits: int = 5,\n    verbose: bool = True,\n)\n</code></pre> <p>Compares multiple classification models based on various metrics and returns the results.</p> <p>This function runs a set of algorithms on the training data, evaluates them on the training and validation sets or using cross-validation, and compiles the performance metrics. The results can be output in different formats, including dictionary, pandas DataFrame, or a formatted table.</p> <p>Parameters:</p> <ul> <li> <code>output</code>           \u2013            <p>The format of the output. It can be: - \"dict\": Returns the results as a dictionary (default). - \"dataframe\": Returns the results as a pandas DataFrame. - \"table\": Prints the results as a formatted table. - \"only_score\": Returns only the accuracy scores in a simplified dictionary.</p> </li> </ul> If True, the function evaluates the models using a train-validation split. <p>If False, the function uses cross-validation. Default is True.</p> <p>Returns:</p> <ul> <li>           \u2013            <p>dict or pd.DataFrame or None</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the task type is not \"classification\" or \"regression\".</p> </li> </ul> <p>Examples: <pre><code>dataset = Dataset(dataframe, norm=True, test_size=0.3, seed=123)\ndataset.fit(features=features,target=target,t=\"classification\")\nclassifier = Classification(dataset, algorithm='random_forest')\nresults = classifier.compare_model(output='dataframe', train_val=True)\nprint(results)\n</code></pre></p>"},{"location":"classification/#optialgo.Classification.score","title":"score","text":"<pre><code>score(y_true, y_pred, metric='accuracy')\n</code></pre> <p>Calculates the score based on the predicted and true target values.</p> <p>Parameters:</p> <ul> <li> <code>y_true</code>               (<code>array - like</code>)           \u2013            <p>The true target values.</p> </li> <li> <code>y_pred</code>               (<code>array - like</code>)           \u2013            <p>The predicted target values.</p> </li> <li> <code>metric</code>               (<code>str</code>, default:                   <code>'accuracy'</code> )           \u2013            <p>The scoring metric to use. Default is 'accuracy'.                     Other options depend on the problem type:                     - For multiclass classification: 'precision', 'recall', 'f1', 'accuracy'                     - For binary classification or regression: 'accuracy', 'precision', 'recall', 'f1', 'r2'                     See sklearn.metrics for available metrics.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>          \u2013            <p>The score calculated based on the specified metric.</p> </li> </ul> Note <p>This method calculates the score based on the predicted and true target values. For multiclass classification, it uses weighted averaging for precision, recall, and F1 score. For other problem types, it returns the specified metric score directly.</p>"},{"location":"classification/#optialgo.Classification.score_report","title":"score_report","text":"<pre><code>score_report(y_true, y_pred)\n</code></pre> <p>Generates a report containing various metric scores and classification report between true and predicted target values.</p> <p>Parameters:</p> <ul> <li> <code>y_true</code>               (<code>array - like</code>)           \u2013            <p>The true target values.</p> </li> <li> <code>y_pred</code>               (<code>array - like</code>)           \u2013            <p>The predicted target values.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>          \u2013            <p>A dictionary containing metric scores calculated for each metric defined in the METRICS dictionary   along with the classification report.</p> </li> </ul> Note <p>This method generates a report containing various metric scores and classification report between true and predicted target values. It calculates metric scores for each metric defined in the METRICS dictionary and includes the classification report generated using scikit-learn's classification_report function.</p>"},{"location":"dataset/","title":"Dataset","text":""},{"location":"dataset/#optialgo.Dataset","title":"Dataset","text":"<pre><code>Dataset(\n    dataframe: DataFrame,\n    norm: bool = False,\n    test_size: float = 0.2,\n    seed: int = 42,\n)\n</code></pre> <p>Parameters:</p> <ul> <li> <code>dataframe</code>               (<code>DataFrame</code>)           \u2013            <p>The input dataframe containing the data to be processed and used for model training.</p> </li> <li> <code>norm</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>A flag indicating whether to normalize the features. Default is False.</p> </li> <li> <code>test_size</code>               (<code>float</code>, default:                   <code>0.2</code> )           \u2013            <p>The proportion of the dataset to include in the test split. Default is 0.2 (20%).</p> </li> <li> <code>seed</code>               (<code>int</code>, default:                   <code>42</code> )           \u2013            <p>The random seed for reproducibility of the train-test split. Default is 42.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If there are missing values in the input dataframe, an error is raised with information on which columns contain missing values.</p> </li> </ul> <p>Examples: <pre><code>df = pd.read_csv(\"house_prices.csv\")\ndataset = Dataset(dataframe=df)\n</code></pre></p>"},{"location":"dataset/#optialgo.Dataset.fit","title":"fit","text":"<pre><code>fit(\n    features: list,\n    target: Optional[str],\n    t: Literal[\"classification\", \"regression\"],\n    encoder: dict = None,\n    ci=False,\n)\n</code></pre> <p>Prepares and fits the dataset for a machine learning task by performing necessary preprocessing steps.</p> <p>Parameters:</p> <ul> <li> <code>features</code>               (<code>list</code>)           \u2013            <p>A list of feature column names to be used for model training.</p> </li> <li> <code>target</code>               (<code>Optional[str]</code>)           \u2013            <p>The name of the target column.</p> </li> <li> <code>t</code>               (<code>Literal['classification', 'regression']</code>)           \u2013            <p>classification or regression</p> </li> <li> <code>encoder</code>               (<code>dict</code>, default:                   <code>None</code> )           \u2013            <p>A dictionary specifying custom encoders for specific columns. If None, default encoders are used.</p> </li> <li> <code>check_imbalance</code>           \u2013            <p>If True, checks for class imbalance in the target column for classification tasks. If an imbalance is detected, it triggers the imbalance handling procedure.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>t</code>           \u2013            <p>The type of machine learning task (<code>clustering</code>, <code>classification</code>, or <code>regression</code>).</p> </li> <li> <code>class_type</code>           \u2013            <p>The classification type (<code>binary</code> or <code>multiclass</code>) if the task is classification.</p> </li> <li> <code>train</code>           \u2013            <p>The preprocessed training dataset.</p> </li> <li> <code>test</code>           \u2013            <p>The preprocessed testing dataset.</p> </li> <li> <code>pipeline</code>           \u2013            <p>The preprocessing pipeline used for transforming the data.</p> </li> <li> <code>features</code>           \u2013            <p>The list of feature names after preprocessing.</p> </li> <li> <code>feature_names</code>           \u2013            <p>The original feature names before preprocessing.</p> </li> <li> <code>target</code>           \u2013            <p>The target column name.</p> </li> <li> <code>label_encoder</code>           \u2013            <p>The label encoder used for encoding the target column if it is categorical.</p> </li> </ul> Notes <p>This method performs the following steps:     <pre><code>1. Determines the task type (clustering, classification, or regression) based on the target column.\n2. Encodes the target column if it is categorical.\n3. Checks for class imbalance if `ci` is True.\n4. Splits the dataset into training and testing sets.\n5. Applies preprocessing to the features using the specified or default encoders.\n6. Stores the preprocessed training and testing datasets for model training.\n</code></pre></p> <p>Examples: <pre><code>dataset = Dataset(dataframe=df)\ndataset.fit(features=[\"feature1\", \"feature2\", \"feature_3\"], target='target_column', t= \"classification\", check_imbalance=True)\n\n# if with custom encoder\nencoder = {\"one_hot\":[\"feature_1\",\"feature_2\"], \"target_mean\": [\"feature_3\"]}\ndataset.fit(features=[\"feature1\", \"feature2\", \"feature_3\"], target='target_column', t= \"classification\", check_imbalance=True, encoder= encoder)\n</code></pre></p>"},{"location":"dataset/#optialgo.Dataset.flow_from_array","title":"flow_from_array","text":"<pre><code>flow_from_array(X: ndarray) -&gt; ndarray\n</code></pre> <p>Transforms the input array using the preprocessing pipeline.</p> <p>Parameters:</p> <ul> <li> <code>X</code>           \u2013            <p>The input array to be transformed. It should have the same number of features as the training data and in the same order.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>The transformed data as a NumPy array.</p> </li> </ul> <p>Examples: <pre><code>input_array = np.array([[1, 2, 3], [4, 5, 6]])\ntransformed_array = dataset.flow_from_array(input_array)\nprint(transformed_array.shape)\n# output : (2, 3)\n# Assuming the pipeline transforms it into 3 features\n</code></pre></p>"},{"location":"dataset/#optialgo.Dataset.flow_from_dataframe","title":"flow_from_dataframe","text":"<pre><code>flow_from_dataframe(X: DataFrame) -&gt; ndarray\n</code></pre> <p>Transforms the input dataframe using the preprocessing pipeline.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>DataFrame</code>)           \u2013            <p>The input dataframe to be transformed.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>np.ndarray: The transformed data as a NumPy array.</p> </li> </ul> <p>Examples: <pre><code>new_data = pd.DataFrame({\"col_a\": [1,2,3],\"col_b\":[1,1,1], \"col_c\" : [2,2,2]})\ntransformed_X = dataset.flow_from_dataframe(new_data)\nprint(transformed_X.shape)\n# output : (3,3)\n</code></pre></p>"},{"location":"dataset/#optialgo.Dataset.get_label","title":"get_label","text":"<pre><code>get_label(y_pred: ndarray) -&gt; ndarray\n</code></pre> <p>Converts predicted numerical labels back to their original categorical labels using the label encoder.</p> <p>Parameters:</p> <ul> <li> <code>y_pred</code>               (<code>ndarray</code>)           \u2013            <p>The predicted numerical labels to be converted.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>The original categorical labels corresponding to the numerical predictions.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the label encoder has not been fitted or is not available.</p> </li> </ul> <p>Examples: <pre><code>y_pred = np.array([0, 1, 2])\noriginal_labels = dataset.get_label(y_pred)\nprint(original_labels)\n# output : array(['class1', 'class2', 'class3'], dtype=object)\n</code></pre></p>"},{"location":"dataset/#optialgo.Dataset.get_x_y","title":"get_x_y","text":"<pre><code>get_x_y()\n</code></pre> <p>Splits the preprocessed training and testing data into features and target arrays.</p> <p>Returns:</p> <ul> <li> <code>tuple</code>          \u2013            <p>A tuple containing four elements: X_train, X_test, y_train, y_test</p> </li> </ul> <p>Examples: <pre><code>X_train, X_test, y_train, y_test = dataset.get_x_y()\n</code></pre></p>"},{"location":"dataset/#optialgo.Dataset.save","title":"save","text":"<pre><code>save()\n</code></pre> <p>Serialize and save the dataset object using pickle.</p> <p>Returns:</p> <ul> <li> <code>bytes</code>          \u2013            <p>Serialized representation of the optialgo object.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>PickleError</code>             \u2013            <p>If serialization fails.</p> </li> </ul>"},{"location":"dataset/#properties","title":"Properties","text":""},{"location":"dataset/#optialgo.Dataset.ENCODERS","title":"ENCODERS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ENCODERS = {\n    \"target_mean\": TargetEncoder(),\n    \"one_hot\": OneHotEncoder(),\n    \"ordinal\": OrdinalEncoder(),\n}\n</code></pre>"},{"location":"dataset/#optialgo.Dataset.dataframe","title":"dataframe  <code>property</code>","text":"<pre><code>dataframe\n</code></pre>"},{"location":"dataset/#optialgo.Dataset.train","title":"train  <code>property</code>","text":"<pre><code>train: DataFrame\n</code></pre>"},{"location":"dataset/#optialgo.Dataset.test","title":"test  <code>property</code>","text":"<pre><code>test\n</code></pre>"},{"location":"dataset/#optialgo.Dataset.feature_names","title":"feature_names  <code>property</code>","text":"<pre><code>feature_names\n</code></pre>"},{"location":"dataset/#optialgo.Dataset.label_encoder","title":"label_encoder  <code>property</code>","text":"<pre><code>label_encoder\n</code></pre>"},{"location":"dataset/#optialgo.Dataset.pipeline","title":"pipeline  <code>property</code>","text":"<pre><code>pipeline\n</code></pre>"},{"location":"dataset/#optialgo.Dataset.target","title":"target  <code>property</code>","text":"<pre><code>target\n</code></pre>"},{"location":"regression/","title":"Regression","text":""},{"location":"regression/#optialgo.Regression","title":"Regression","text":"<pre><code>Regression(dataset: Dataset, algorithm: str = None)\n</code></pre> <p>               Bases: <code>Parent</code></p>"},{"location":"regression/#optialgo.Regression.compare_model","title":"compare_model","text":"<pre><code>compare_model(\n    output: str = \"dict\",\n    train_val: bool = False,\n    n_splits: int = 5,\n    verbose: bool = True,\n)\n</code></pre> <p>Compares multiple regression models based on various metrics and returns the results.</p> <p>This function evaluates a set of algorithms on the training and validation sets or using cross-validation, and compiles performance metrics. The results can be output in different formats, including dictionary, pandas DataFrame, or a formatted table.</p> <p>Parameters:</p> <ul> <li> <code>output</code>           \u2013            <p>The format of the output. It can be: - \"dict\": Returns the results as a dictionary (default). - \"dataframe\": Returns the results as a pandas DataFrame. - \"table\": Prints the results as a formatted table. - \"only_score\": Returns only the Mean Absolute Percentage Error (MAPE) scores in a simplified dictionary.</p> </li> <li> <code>train_val</code>           \u2013            <p>If True, the function evaluates the models using a train-validation split. If False, the function uses cross-validation. Default is False.</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>dict or pd.DataFrame or None: The function returns results based on the <code>output</code> parameter: - If <code>output</code> is \"dict\", it returns a dictionary of the results. - If <code>output</code> is \"dataframe\", it returns a pandas DataFrame of the results. - If <code>output</code> is \"table\", it prints the results as a formatted table. - If <code>output</code> is \"only_score\", it returns a dictionary with only the MAPE scores.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If an invalid output type is provided.</p> </li> </ul> <p>Examples: <pre><code>dataset = Dataset(dataframe, norm=True, test_size=0.3, seed=123)\ndataset.fit(features=features,target=target)\nregressor = Regressor(dataset, algorithm='random_forest')\nresults = regressor.compare_model(output='dataframe', train_val=True)\nprint(results)\n</code></pre></p>"},{"location":"regression/#optialgo.Regression.score","title":"score","text":"<pre><code>score(y_true, y_pred, metric='mean_absolute_error')\n</code></pre> <p>Calculate the evaluation metric for the given true and predicted values.</p> <p>This method computes a specified error metric based on the true and predicted values of the target variable. It uses the metrics stored in the <code>self.METRICS</code> dictionary.</p> <p>Parameters:</p> <ul> <li> <code>y_true</code>           \u2013            <p>True values of the target variable.</p> </li> <li> <code>y_pred</code>           \u2013            <p>Predicted values of the target variable.</p> </li> <li> <code>metric</code>           \u2013            <p>The metric to be used for evaluating the predictions. Default is \"mean_absolute_error\". Possible values include: - \"mean_absolute_error\" - \"mean_squared_error\" - \"mean_absolute_percentage_error\" - Other metrics defined in <code>self.METRICS</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>          \u2013            <p>The computed error metric value.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>KeyError</code>             \u2013            <p>If the specified metric is not found in <code>self.METRICS</code>.</p> </li> </ul> <p>Examples: <pre><code>y_true = [3.0, -0.5, 2.0, 7.0]\ny_pred = [2.5, 0.0, 2.0, 8.0]\nregressor = Regressor(dataset, algorithm='linear_regression')\nmae = regressor.score(y_true, y_pred, metric='mean_absolute_error')\nprint(mae)\n# output : 0.5\n</code></pre></p>"},{"location":"regression/#optialgo.Regression.score_report","title":"score_report","text":"<pre><code>score_report(y_true, y_pred)\n</code></pre> <p>Generate a report of evaluation metrics for the given true and predicted values.</p> <p>This method computes various evaluation metrics defined in <code>self.METRICS</code> for the provided true and predicted values of the target variable. It returns a dictionary with the names of the metrics as keys and their computed values as values.</p> <p>Parameters:</p> <ul> <li> <code>y_true</code>           \u2013            <p>True values of the target variable.</p> </li> <li> <code>y_pred</code>           \u2013            <p>Predicted values of the target variable.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>          \u2013            <p>A dictionary containing the names and values of the computed metrics. The keys are</p> </li> <li>           \u2013            <p>the metric names (as defined in <code>self.METRICS</code>) and the values are the corresponding</p> </li> <li>           \u2013            <p>metric values.</p> </li> </ul> <p>Examples: <pre><code>y_true = [3.0, -0.5, 2.0, 7.0]\ny_pred = [2.5, 0.0, 2.0, 8.0]\nregressor = Regressor(dataset, algorithm='linear_regression')\nreport = regressor.score_report(y_true, y_pred)\nfor metric, value in report.items():\n    print(f\"{metric}: {value:.4f}\")\n''' output :\nmean_absolute_error: 0.5000\nmean_squared_error: 0.3750\nmean_absolute_percentage_error: 0.1271\n'''\n</code></pre></p>"},{"location":"text_dataset/","title":"Text dataset","text":""},{"location":"text_dataset/#optialgo.TextDataset","title":"TextDataset","text":"<pre><code>TextDataset(\n    dataframe: DataFrame,\n    test_size: float = 0.2,\n    seed: int = 42,\n)\n</code></pre> <p>A class to handle text data preprocessing and manipulation for machine learning tasks.</p> <p>Parameters:</p> <ul> <li> <code>dataframe</code>               (<code>DataFrame</code>)           \u2013            <p>The input dataframe containing the dataset.</p> </li> <li> <code>test_size</code>               (<code>float</code>, default:                   <code>0.2</code> )           \u2013            <p>Proportion of the dataset to include in the test split (default is 0.2).</p> </li> <li> <code>seed</code>               (<code>int</code>, default:                   <code>42</code> )           \u2013            <p>Random seed for reproducibility (default is 42).</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If there are missing values in the dataframe.</p> </li> </ul>"},{"location":"text_dataset/#optialgo.TextDataset.fit","title":"fit","text":"<pre><code>fit(\n    feature: str,\n    target: Optional[str],\n    t: Literal[\"classification\", \"regression\"],\n    vectorizer: Union[\n        Literal[\"tfidf\", \"count_vect\"], Tokenizer\n    ] = \"tfidf\",\n    ci: bool = False,\n)\n</code></pre> <p>Fits the preprocessing pipeline and prepares the data for training and testing.</p> <p>Parameters:</p> <ul> <li> <code>feature</code>               (<code>str</code>)           \u2013            <p>The feature column to use for training.</p> </li> <li> <code>target</code>           \u2013            <p>The target column to use for training.</p> </li> <li> <code>t</code>           \u2013            <p>The type of task (classification or regression).</p> </li> <li> <code>vectorizer</code>           \u2013            <p>The vectorizer to use for preprocessing (default is \"tfidf\").</p> </li> <li> <code>verbose</code>           \u2013            <p>Whether to print verbose output (default is False).</p> </li> <li> <code>ci</code>           \u2013            <p>Whether to check for class imbalance (default is False).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>TextDataset</code>          \u2013            <p>The fitted TextDataset object.</p> </li> </ul>"},{"location":"text_dataset/#optialgo.TextDataset.flow_from_array","title":"flow_from_array","text":"<pre><code>flow_from_array(X: ndarray) -&gt; ndarray\n</code></pre> <p>Transforms the given array using the preprocessing pipeline.</p> <p>Parameters:</p> <ul> <li> <code>X</code>           \u2013            <p>The input array to transform.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>The transformed array.</p> </li> </ul>"},{"location":"text_dataset/#optialgo.TextDataset.flow_from_dataframe","title":"flow_from_dataframe","text":"<pre><code>flow_from_dataframe(X: DataFrame) -&gt; ndarray\n</code></pre> <p>Transforms the feature column of the given dataframe using the preprocessing pipeline.</p> <p>Parameters:</p> <ul> <li> <code>X</code>           \u2013            <p>The input dataframe to transform.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>The transformed feature column.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>KeyError</code>             \u2013            <p>If the feature column is not in the dataframe.</p> </li> </ul>"},{"location":"text_dataset/#optialgo.TextDataset.get_label","title":"get_label","text":"<pre><code>get_label(y_pred: ndarray) -&gt; ndarray\n</code></pre> <p>Converts predicted labels back to their original form using the label encoder.</p> <p>Parameters:</p> <ul> <li> <code>y_pred</code>           \u2013            <p>The predicted labels.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>The original labels.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the label encoder is not found.</p> </li> </ul>"},{"location":"text_dataset/#optialgo.TextDataset.get_x_y","title":"get_x_y","text":"<pre><code>get_x_y() -&gt; tuple\n</code></pre> <p>Returns the train and test splits of features and labels.</p> <p>Returns:</p> <ul> <li> <code>tuple</code>           \u2013            <p>The training features, testing features, training labels, and testing labels.</p> </li> </ul>"},{"location":"text_dataset/#properties","title":"Properties","text":""},{"location":"text_dataset/#optialgo.TextDataset.dataframe","title":"dataframe  <code>property</code>","text":"<pre><code>dataframe\n</code></pre>"},{"location":"text_dataset/#optialgo.TextDataset.train","title":"train  <code>property</code>","text":"<pre><code>train\n</code></pre>"},{"location":"text_dataset/#optialgo.TextDataset.test","title":"test  <code>property</code>","text":"<pre><code>test\n</code></pre>"},{"location":"text_dataset/#optialgo.TextDataset.pipeline","title":"pipeline  <code>property</code>","text":"<pre><code>pipeline\n</code></pre>"},{"location":"text_dataset/#optialgo.TextDataset.feature","title":"feature  <code>property</code>","text":"<pre><code>feature\n</code></pre>"},{"location":"text_dataset/#optialgo.TextDataset.vectorizer","title":"vectorizer  <code>property</code>","text":"<pre><code>vectorizer\n</code></pre>"},{"location":"text_dataset/#optialgo.TextDataset.label_encoder","title":"label_encoder  <code>property</code>","text":"<pre><code>label_encoder\n</code></pre>"},{"location":"tutorials/make_dataset/","title":"Make Dataset","text":"<pre><code>from sklearn.datasets import load_iris\nfrom optialgo import Dataset\nimport pandas as pd\n\niris = load_iris()\n\nX = iris.data.copy()\ny = [iris.target_names[target] for target in iris.target]\ndf = pd.DataFrame(X,columns=iris.feature_names)\ndf[\"target\"] = y\n\ndataset = Dataset(df)\nprint(dataset.dataframe)\n</code></pre> <pre><code>     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)     target\n0                  5.1               3.5                1.4               0.2     setosa\n1                  4.9               3.0                1.4               0.2     setosa\n2                  4.7               3.2                1.3               0.2     setosa\n3                  4.6               3.1                1.5               0.2     setosa\n4                  5.0               3.6                1.4               0.2     setosa\n..                 ...               ...                ...               ...        ...\n145                6.7               3.0                5.2               2.3  virginica\n146                6.3               2.5                5.0               1.9  virginica\n147                6.5               3.0                5.2               2.0  virginica\n148                6.2               3.4                5.4               2.3  virginica\n149                5.9               3.0                5.1               1.8  virginica\n\n[150 rows x 5 columns]\n</code></pre> <pre><code>features = iris.feature_names\ntarget = \"target\"\n\ndataset.fit(features=features,target=target)\nprint(dataset.train)\n</code></pre> <pre><code>     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  target\n0                  4.4               2.9                1.4               0.2       0\n1                  4.9               2.5                4.5               1.7       2\n2                  6.8               2.8                4.8               1.4       1\n3                  4.9               3.1                1.5               0.1       0\n4                  5.5               2.5                4.0               1.3       1\n..                 ...               ...                ...               ...     ...\n115                4.9               3.6                1.4               0.1       0\n116                4.7               3.2                1.3               0.2       0\n117                5.5               4.2                1.4               0.2       0\n118                6.9               3.1                4.9               1.5       1\n119                4.6               3.1                1.5               0.2       0\n\n[120 rows x 5 columns]\n</code></pre>"},{"location":"utils/dimensionality_reduction/","title":"Dimensionality Reduction","text":""},{"location":"utils/dimensionality_reduction/#optialgo.pca","title":"pca","text":"<pre><code>pca(\n    dataframe: DataFrame, features: list, n_components: int\n) -&gt; ndarray\n</code></pre> <p>Applies Principal Component Analysis (PCA) to reduce the dimensionality of the input data.</p> <p>Parameters:</p> <ul> <li> <code>dataframe</code>           \u2013            <p>The input dataframe containing the features.</p> </li> <li> <code>features</code>           \u2013            <p>A list of feature column names to be used for PCA.</p> </li> <li> <code>n_components</code>           \u2013            <p>The number of principal components to retain.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>np.ndarray: The transformed data after PCA.</p> </li> </ul> <p>Examples <pre><code>import pandas as pd\nfrom optialgo import PCA\ndf = pd.DataFrame({\n    'feature1': [1, 2, 3],\n    'feature2': [4, 5, 6],\n    'feature3': [7, 8, 9]\n})\ntransformed_data = pca(df, features=['feature1', 'feature2', 'feature3'], n_components=2)\ntransformed_data.shape\n# output : (3, 2)  # Assuming 3 samples and 2 principal components\n</code></pre></p>"},{"location":"utils/feature_selection/","title":"Feature Selection","text":""},{"location":"utils/feature_selection/#optialgo.feature_selection","title":"feature_selection","text":"<pre><code>feature_selection(\n    dataframe: DataFrame,\n    target: str,\n    n_features: int,\n    threshold: int = 0.0,\n    features: list = None,\n    show_score: bool = True,\n) -&gt; dict\n</code></pre> <p>Perform feature selection using various methods and evaluate model performance.</p> <p>This function applies multiple feature selection methods to a given dataframe, fits a classification or regression model based on the target variable type, and evaluates the model performance for each set of selected features.</p> <p>Parameters:</p> <ul> <li> <code>dataframe</code>           \u2013            <p>The input dataframe containing features and the target variable.</p> </li> <li> <code>target</code>           \u2013            <p>The name of the target variable column in the dataframe.</p> </li> <li> <code>n_features</code>           \u2013            <p>The number of top features to select using feature selection methods.</p> </li> <li> <code>threshold</code>           \u2013            <p>The threshold for variance threshold feature selection. Default is 0.0.</p> </li> <li> <code>features</code>           \u2013            <p>A list of feature names to consider for selection. If not provided, all columns except the target column are used.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code> (              <code>dict</code> )          \u2013            <p>A dictionary where keys are the names of feature selection methods and values are the sets of selected features.</p> </li> </ul> <p>Examples: <pre><code>import pandas as pd\nfrom optialgo import feature_selection\nselected_features = feature_selection(dataframe=df, target=\"target\", n_features=10)\nprint(selected_features)\n# output :{\n    'all': ['feature1', 'feature2', ...],\n    'f_mutual': ['feature1', 'feature3', ...],\n    'f_anova': ['feature2', 'feature4', ...],\n    ...\n}\n</code></pre></p>"},{"location":"utils/feature_selection/#optialgo.feature_select_rfe","title":"feature_select_rfe","text":"<pre><code>feature_select_rfe(\n    X: DataFrame, y: DataFrame, n_features: int, t: str\n)\n</code></pre> <p>Perform feature selection using Recursive Feature Elimination (RFE).</p> <p>This method selects the top <code>n_features</code> from the input dataframe <code>X</code> using Recursive Feature Elimination with a specified model type for either classification or regression tasks.</p> <p>Parameters:</p> <ul> <li> <code>X</code>           \u2013            <p>The input dataframe containing feature values.</p> </li> <li> <code>y</code>           \u2013            <p>The target values corresponding to the input features.</p> </li> <li> <code>n_features</code>           \u2013            <p>The number of top features to select.</p> </li> <li> <code>t</code>           \u2013            <p>The type of task: \"classification\" or \"regression\". Determines which model to use for RFE.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>          \u2013            <p>A list of the names of the selected features.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If <code>t</code> is neither \"classification\" nor \"regression\".</p> </li> </ul> <p>Examples: <pre><code>from sklearn.datasets import load_iris\nfrom optialgo import feature_select_rfe\nimport pandas as pd\ndata = load_iris()\nX = pd.DataFrame(data.data, columns=data.feature_names)\ny = pd.DataFrame(data.target, columns=[\"target\"])\nselected_features = feature_select_rfe(X, y, n_features=2, t=\"classification\")\nprint(selected_features)\n# output : ['petal width (cm)', 'petal length (cm)']\n</code></pre></p>"},{"location":"utils/feature_selection/#optialgo.feature_select_anova","title":"feature_select_anova","text":"<pre><code>feature_select_anova(\n    X: DataFrame, y: DataFrame, n_features: int\n)\n</code></pre> <p>Perform feature selection using ANOVA F-test.</p> <p>This method selects the top <code>n_features</code> features from the input dataframe <code>X</code> based on the ANOVA F-test. It uses the <code>SelectKBest</code> class with the <code>f_classif</code> scoring function to rank features by their importance.</p> <p>Parameters:</p> <ul> <li> <code>X</code>           \u2013            <p>The input dataframe containing feature values.</p> </li> <li> <code>y</code>           \u2013            <p>The target values corresponding to the input features.</p> </li> <li> <code>n_features</code>           \u2013            <p>The number of top features to select.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>          \u2013            <p>A list of the names of the selected features.</p> </li> </ul> <p>Examples: <pre><code>from sklearn.datasets import load_iris\nfrom optialgo import feature_select_anova\nimport pandas as pd\ndata = load_iris()\nX = pd.DataFrame(data.data, columns=data.feature_names)\ny = pd.DataFrame(data.target, columns=[\"target\"])\nselected_features = feature_select_anova(X, y, n_features=2)\nprint(selected_features)\n# output : ['petal length (cm)', 'petal width (cm)']\n</code></pre></p>"},{"location":"utils/feature_selection/#optialgo.feature_select_chi_square","title":"feature_select_chi_square","text":"<pre><code>feature_select_chi_square(\n    X: DataFrame, y: DataFrame, n_features: int\n) -&gt; list\n</code></pre> <p>Selects the top <code>n_features</code> based on the chi-square statistic for classification tasks.</p> <p>This function evaluates the importance of categorical features in a dataset using the chi-square statistical test. It selects the most important features according to the specified number of features to select.</p> <p>Parameters:</p> <ul> <li> <code>X</code>           \u2013            <p>The input dataframe containing the feature columns.</p> </li> <li> <code>y</code>           \u2013            <p>The target variable column.</p> </li> <li> <code>n_features</code>           \u2013            <p>The number of top features to select based on the chi-square statistic.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code> (              <code>list</code> )          \u2013            <p>A list of the selected feature names ranked by their chi-square scores.</p> </li> </ul> <p>Examples: <pre><code>import pandas as pd\nfrom sklearn.datasets import load_iris\nfrom optialgo import feature_select_chi_square\nfrom sklearn.model_selection import train_test_split\ndata = load_iris()\nX = pd.DataFrame(data.data, columns=data.feature_names)\ny = pd.Series(data.target)\nselected_features = feature_select_chi_square(X, y, n_features=2)\nprint(selected_features)\n# output : ['petal length (cm)', 'petal width (cm)']\n</code></pre></p>"},{"location":"utils/feature_selection/#optialgo.feature_select_fisher_score","title":"feature_select_fisher_score","text":"<pre><code>feature_select_fisher_score(\n    X: DataFrame, y: DataFrame, n_features: int\n) -&gt; list\n</code></pre> <p>Perform feature selection using Fisher Score.</p> <p>This method selects the top <code>n_features</code> from the input dataframe <code>X</code> based on the Fisher Score. Fisher Score is a supervised feature selection method that evaluates the importance of a feature by measuring the discriminative power of each feature with respect to the target <code>y</code>.</p> <p>Parameters:</p> <ul> <li> <code>X</code>           \u2013            <p>The input dataframe containing feature values.</p> </li> <li> <code>y</code>           \u2013            <p>The target values corresponding to the input features.</p> </li> <li> <code>n_features</code>           \u2013            <p>The number of top features to select.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code> (              <code>list</code> )          \u2013            <p>A list of the names of the selected features.</p> </li> </ul> <p>Examples <pre><code>from sklearn.datasets import load_iris\nfrom optialgo import feature_select_fisher_score\nimport pandas as pd\ndata = load_iris()\nX = pd.DataFrame(data.data, columns=data.feature_names)\ny = pd.DataFrame(data.target, columns=[\"target\"])\nselected_features = feature_select_fisher_score(X, y, n_features=2)\nprint(selected_features)\n# output :['petal width (cm)', 'petal length (cm)']\n</code></pre></p>"},{"location":"utils/feature_selection/#optialgo.feature_select_variance_threshold","title":"feature_select_variance_threshold","text":"<pre><code>feature_select_variance_threshold(\n    X: DataFrame, threshold: int\n) -&gt; list\n</code></pre> <p>Perform feature selection using Variance Threshold.</p> <p>This method selects features from the input dataframe <code>X</code> based on a variance threshold. Features with a variance lower than the threshold will be removed, as they are less likely to be informative.</p> <p>Parameters:</p> <ul> <li> <code>X</code>           \u2013            <p>The input dataframe containing feature values.</p> </li> <li> <code>threshold</code>           \u2013            <p>The variance threshold. Features with a variance lower than this value will be removed.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code> (              <code>list</code> )          \u2013            <p>A list of the names of the selected features that have a variance above the threshold.</p> </li> </ul> <p>Examples: <pre><code>from sklearn.datasets import load_iris\nfrom optialgo import feature_select_variance_threshold\nimport pandas as pd\ndata = load_iris()\nX = pd.DataFrame(data.data, columns=data.feature_names)\nselected_features = feature_select_variance_threshold(X, threshold=0.5)\nprint(selected_features)\n# output : ['petal length (cm)', 'petal width (cm)']\n</code></pre></p>"},{"location":"utils/feature_selection/#optialgo.feature_select_information_gain","title":"feature_select_information_gain","text":"<pre><code>feature_select_information_gain(\n    X: DataFrame, y: DataFrame, n_features: int, t: str\n) -&gt; list\n</code></pre> <p>Selects the top <code>n_features</code> based on information gain for classification or regression tasks.</p> <p>This function evaluates the importance of features in a dataset using mutual information. It supports both classification and regression tasks, and selects the most important features according to the specified number of features to select.</p> <p>Parameters:</p> <ul> <li> <code>X</code>           \u2013            <p>The input dataframe containing the feature columns.</p> </li> <li> <code>y</code>           \u2013            <p>The target variable column.</p> </li> <li> <code>n_features</code>           \u2013            <p>The number of top features to select based on information gain.</p> </li> <li> <code>t</code>           \u2013            <p>The type of task. It can be either \"classification\" or \"regression\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code> (              <code>list</code> )          \u2013            <p>A list of the selected feature names ranked by their importance.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If <code>t</code> is not \"classification\" or \"regression\".</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from sklearn.datasets import load_iris\n&gt;&gt;&gt; from optialgo import feature_select_information_gain\n&gt;&gt;&gt; from sklearn.model_selection import train_test_split\n&gt;&gt;&gt; data = load_iris()\n&gt;&gt;&gt; X = pd.DataFrame(data.data, columns=data.feature_names)\n&gt;&gt;&gt; y = pd.Series(data.target)\n&gt;&gt;&gt; selected_features = feature_select_information_gain(X, y, n_features=2, t='classification')\n&gt;&gt;&gt; print(selected_features)\n['petal length (cm)', 'petal width (cm)']\n</code></pre>"},{"location":"utils/handle_missing_values/","title":"Handle Missing Values","text":""},{"location":"utils/handle_missing_values/#optialgo.handling_missing_values","title":"handling_missing_values","text":"<pre><code>handling_missing_values(\n    dataframe: DataFrame,\n    imputation: dict = None,\n    threshold: float = 0.3,\n) -&gt; DataFrame\n</code></pre> <p>Handle missing values in a DataFrame by either imputing or dropping columns based on a threshold.</p> <p>This function handles missing values in the given DataFrame. It can perform custom imputation using the provided dictionary of imputers, drop columns with missing values exceeding a specified threshold, and impute the remaining missing values using median for numerical columns and most frequent value for categorical columns.</p> <p>Args: dataframe : The input DataFrame containing missing values. imputation : A dictionary where keys are column names and values are imputer instances from sklearn.impute. If provided, these imputers will be used to fill missing values in the specified columns. threshold : A float value between 0 and 1 that specifies the maximum allowable fraction of missing values in a column.  Columns with a fraction of missing values greater than or equal to this threshold will be dropped.</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame with missing values handled according to the specified parameters.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the threshold is greater than or equal to 1.</p> </li> </ul> <p>Examples <pre><code>import pandas as pd\nfrom optialgo import handling_missing_values\nfrom sklearn.impute import SimpleImputer\ndata = {'A': [1, 2, None, 4], 'B': [None, 2, 3, 4], 'C': [1, 2, 3, None]}\ndf = pd.DataFrame(data)\nimputer = SimpleImputer(strategy='mean')\nhandled_df = handling_missing_values(df, imputation={'A': imputer}, threshold=0.5)\n</code></pre></p> <p>Notes: <pre><code>1. This function creates a copy of the input DataFrame to avoid modifying the original DataFrame.\n2. Columns with missing values exceeding the specified threshold are dropped.\n3. For remaining columns with missing values, numerical columns are imputed using the median, and categorical columns are imputed using the most frequent value.\n</code></pre></p>"},{"location":"utils/sampling/","title":"Sampling","text":""},{"location":"utils/sampling/#optialgo.sampling","title":"sampling","text":"<pre><code>sampling(\n    dataframe: DataFrame,\n    features: list,\n    target: str,\n    method: Literal[\"smote\", \"over\", \"under\"] = \"smote\",\n    sampling_strategy: str = \"auto\",\n    seed: int = 42,\n)\n</code></pre> <p>Applies sampling techniques to balance the target classes in the dataframe.</p> <p>Parameters:</p> <ul> <li> <code>dataframe</code>           \u2013            <p>The input dataframe containing the features and target column.</p> </li> <li> <code>features</code>           \u2013            <p>A list of feature column names to be used for sampling.</p> </li> <li> <code>target</code>           \u2013            <p>The name of the target column to be balanced.</p> </li> <li> <code>method</code>           \u2013            <p>The sampling method to be used. </p> </li> <li> <code>sampling_strategy</code>           \u2013            <p>The sampling strategy to use. Default is \"auto\".</p> </li> <li> <code>seed</code>           \u2013            <p>The random seed for reproducibility. Default is 42.</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>pd.DataFrame: The dataframe with the target classes balanced according to the specified method.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If an invalid sampling method is provided.</p> </li> </ul> <p>Examples: <pre><code>import pandas as pd\nfrom optialgo import sampling\ndf = pd.DataFrame({\n    'feature1': [1, 2, 3, 4, 5, 6],\n    'feature2': [7, 8, 9, 10, 11, 12],\n    'target': [0, 0, 0, 1, 1, 1]\n})\nsampled_df = sampling(df, features=['feature1', 'feature2'], target='target', method='over')\nsampled_df['target'].value_counts()\n</code></pre></p>"},{"location":"utils/text_preprocessing/","title":"Text Preprocessing","text":""},{"location":"utils/text_preprocessing/#optialgo.f_remove_punctuation","title":"f_remove_punctuation  <code>cached</code>","text":"<pre><code>f_remove_punctuation(\n    text: str, punctuation: str = string.punctuation\n) -&gt; str\n</code></pre> <p>Remove punctuation from a single text string.</p> <p>Parameters:</p> <ul> <li> <code>text</code>           \u2013            <p>The input text from which to remove punctuation.</p> </li> <li> <code>punctuation</code>           \u2013            <p>The punctuation characters to remove, by default string.punctuation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code> (              <code>str</code> )          \u2013            <p>The text with punctuation removed.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.remove_punctuation","title":"remove_punctuation","text":"<pre><code>remove_punctuation(\n    data: List[str], punctuation: str = string.punctuation\n) -&gt; List[str]\n</code></pre> <p>Remove punctuation from a list of texts.</p> <p>Parameters:</p> <ul> <li> <code>data</code>           \u2013            <p>List of texts.</p> </li> <li> <code>punctuation</code>           \u2013            <p>The punctuation characters to remove, by default string.punctuation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>List[str]</code>           \u2013            <p>List[str] : List of texts without punctuation.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.f_remove_digits","title":"f_remove_digits","text":"<pre><code>f_remove_digits(text: str) -&gt; str\n</code></pre> <p>Remove digits from a single text string.</p> <p>Parameters:</p> <ul> <li> <code>text</code>           \u2013            <p>The input text from which to remove digits.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code> (              <code>str</code> )          \u2013            <p>The text with digits removed.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.remove_digits","title":"remove_digits","text":"<pre><code>remove_digits(data: List[str]) -&gt; List[str]\n</code></pre> <p>Remove digits from a list of texts.</p> <p>Parameters:</p> <ul> <li> <code>data</code>           \u2013            <p>List of texts.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>List[str]</code>           \u2013            <p>List[str]: List of texts without digits.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.f_remove_url","title":"f_remove_url  <code>cached</code>","text":"<pre><code>f_remove_url(text) -&gt; str\n</code></pre> <p>Remove URLs from a single text string.</p> <p>Parameters:</p> <ul> <li> <code>text</code>           \u2013            <p>The input text from which to remove URLs.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code> (              <code>str</code> )          \u2013            <p>The text with URLs removed.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.remove_url","title":"remove_url","text":"<pre><code>remove_url(data: List[str]) -&gt; List[str]\n</code></pre> <p>Remove URLs from a list of texts.</p> <p>Parameters:</p> <ul> <li> <code>data</code>           \u2013            <p>List of texts.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>List[str]</code>           \u2013            <p>List[str]: List of texts without URLs.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.f_remove_emoji","title":"f_remove_emoji  <code>cached</code>","text":"<pre><code>f_remove_emoji(text: str) -&gt; str\n</code></pre> <p>Remove emojis from a single text string.</p> <p>Parameters:</p> <ul> <li> <code>text</code>           \u2013            <p>The input text from which to remove emojis.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code> (              <code>str</code> )          \u2013            <p>The text with emojis removed.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.remove_emoji","title":"remove_emoji","text":"<pre><code>remove_emoji(data: List[str]) -&gt; List[str]\n</code></pre> <p>Remove emojis from a list of texts.</p> <p>Parameters:</p> <ul> <li> <code>data</code>           \u2013            <p>List of texts.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>List[str]</code>           \u2013            <p>List[str]: List of texts without emojis.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.f_remove_non_latin","title":"f_remove_non_latin  <code>cached</code>","text":"<pre><code>f_remove_non_latin(text: str) -&gt; str\n</code></pre> <p>Remove non-Latin characters from a single text string.</p> <p>Parameters:</p> <ul> <li> <code>text</code>           \u2013            <p>The input text from which to remove non-Latin characters.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code> (              <code>str</code> )          \u2013            <p>The text with non-Latin characters removed.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.remove_non_latin","title":"remove_non_latin","text":"<pre><code>remove_non_latin(data: List[str]) -&gt; List[str]\n</code></pre> <p>Remove non-Latin characters from a list of texts.</p> <p>Parameters:</p> <ul> <li> <code>data</code>           \u2013            <p>List of texts.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>List[str]</code>           \u2013            <p>List[str]: List of texts without non-Latin characters.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.F_TEXT_CLEAN","title":"F_TEXT_CLEAN  <code>module-attribute</code>","text":"<pre><code>F_TEXT_CLEAN = [\n    \"remove_punctuation\",\n    \"remove_digits\",\n    \"remove_url\",\n    \"remove_emoji\",\n    \"remove_non_latin\",\n]\n</code></pre>"},{"location":"utils/text_preprocessing/#optialgo.lower_text","title":"lower_text","text":"<pre><code>lower_text(data: List[str]) -&gt; List[str]\n</code></pre>"},{"location":"utils/text_preprocessing/#optialgo.f_regex_word_tokenize","title":"f_regex_word_tokenize","text":"<pre><code>f_regex_word_tokenize(\n    text: str, pattern: Pattern[str]\n) -&gt; Tuple[str]\n</code></pre> <p>Tokenize a text string using a regex pattern.</p> <p>Parameters:</p> <ul> <li> <code>text</code>           \u2013            <p>The input text to tokenize.</p> </li> <li> <code>pattern</code>           \u2013            <p>The regex pattern to use for tokenization.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tuple[str]</code>           \u2013            <p>Tuple[str]: A tuple of tokens.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.f_word_tokenize","title":"f_word_tokenize","text":"<pre><code>f_word_tokenize(text: str)\n</code></pre> <p>Tokenize a text string using NLTK's word_tokenize.</p> <p>Parameters:</p> <ul> <li> <code>text</code>           \u2013            <p>The input text to tokenize.</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>Tuple[str]: A tuple of tokens.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.word_tokenize","title":"word_tokenize","text":"<pre><code>word_tokenize(\n    data: List[str], pattern: Optional[Pattern[str]] = None\n) -&gt; List[Tuple[str, ...]]\n</code></pre> <p>Tokenize a list of text strings.</p> <p>Parameters:</p> <ul> <li> <code>data</code>           \u2013            <p>List of texts to tokenize.</p> </li> <li> <code>pattern</code>           \u2013            <p>The regex pattern to use for tokenization, by default None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>List[Tuple[str, ...]]</code>           \u2013            <p>List[Tuple[str, ...]]: List of tuples of tokens.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.token_to_str","title":"token_to_str","text":"<pre><code>token_to_str(data: List[Tuple[str]]) -&gt; List[str]\n</code></pre> <p>Convert a list of token tuples to a list of strings.</p> <p>Parameters:</p> <ul> <li> <code>data</code>           \u2013            <p>List of token tuples.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>List[str]</code>           \u2013            <p>List[str]: List of strings joined from tokens.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.find_duplicates","title":"find_duplicates","text":"<pre><code>find_duplicates(data: List[str]) -&gt; dict\n</code></pre> <p>Find duplicates in a list of strings and return their indices.</p> <p>Parameters:</p> <ul> <li> <code>data</code>           \u2013            <p>List of strings to check for duplicates.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code> (              <code>dict</code> )          \u2013            <p>A dictionary where keys are duplicate strings and values are lists of their indices.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.text_clean","title":"text_clean","text":"<pre><code>text_clean(\n    data: List[str],\n    punctuation: Optional[str] = string.punctuation,\n    lower: bool = True,\n    digits: bool = True,\n    emoji: bool = True,\n    duplicates: bool = True,\n    url: bool = True,\n    non_latin: bool = True,\n    return_token: bool = False,\n    return_dataframe: bool = False,\n    verbose: bool = False,\n    pattern: Optional[Pattern[str]] = None,\n)\n</code></pre> <p>Clean a list of text data based on specified parameters.</p> <p>Parameters:</p> <ul> <li> <code>data</code>           \u2013            <p>List of strings to clean.</p> </li> <li> <code>punctuation</code>           \u2013            <p>Punctuation characters to remove, by default string.punctuation.</p> </li> <li> <code>lower</code>           \u2013            <p>Convert text to lowercase, by default True.</p> </li> <li> <code>digits</code>           \u2013            <p>Remove digits from text, by default True.</p> </li> <li> <code>emoji</code>           \u2013            <p>Remove emojis from text, by default True.</p> </li> <li> <code>duplicates</code>           \u2013            <p>Remove duplicate entries from data, by default True.</p> </li> <li> <code>url</code>           \u2013            <p>Remove URLs from text, by default True.</p> </li> <li> <code>non_latin</code>           \u2013            <p>Remove non-Latin characters from text, by default True.</p> </li> <li> <code>return_token</code>           \u2013            <p>Tokenize text and return tokens, by default False.</p> </li> <li> <code>return_dataframe</code>           \u2013            <p>Return result as a Pandas DataFrame, by default False.</p> </li> <li> <code>verbose</code>           \u2013            <p>Display progress using tqdm, by default False.</p> </li> <li> <code>pattern</code>           \u2013            <p>Regex pattern for tokenization, by default None.</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>List[str]: Cleaned list of text data.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If return_dataframe is True but lengths of data and cleaned data don't match.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.get_stopwords_en","title":"get_stopwords_en","text":"<pre><code>get_stopwords_en() -&gt; List[str]\n</code></pre> <p>Get English stopwords from NLTK corpus.</p> <p>Returns:</p> <ul> <li> <code>List[str]</code>           \u2013            <p>List[str]: List of English stopwords.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.get_stopwords_idn","title":"get_stopwords_idn","text":"<pre><code>get_stopwords_idn() -&gt; List[str]\n</code></pre> <p>Get Indonesian stopwords from NLTK corpus.</p> <p>Returns:</p> <ul> <li> <code>List[str]</code>           \u2013            <p>List[str] List of Indonesian stopwords.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.f_stopwords","title":"f_stopwords","text":"<pre><code>f_stopwords(\n    token: Union[Tuple[str], str],\n    stopwords: Set[str],\n    return_token: bool = False,\n) -&gt; Union[Tuple[str, ...], str]\n</code></pre> <p>Remove stopwords from a token or tuple of tokens.</p> <p>Parameters:</p> <ul> <li> <code>token</code>           \u2013            <p>Token or tuple of tokens to filter.</p> </li> <li> <code>stopwords</code>           \u2013            <p>Set of stopwords to filter out.</p> </li> <li> <code>return_token</code>           \u2013            <p>Whether to return tokens (True) or a joined string (False), by default False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Union[Tuple[str, ...], str]</code>           \u2013            <p>Union[Tuple[str, ...], str]: Filtered tokens or joined string without stopwords.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.remove_stopwords","title":"remove_stopwords","text":"<pre><code>remove_stopwords(\n    tokens: List[Tuple[str]],\n    lang: str,\n    stopwords: Optional[List[str]] = None,\n    additional: Optional[List[str]] = None,\n    return_token: bool = True,\n    verbose: bool = False,\n) -&gt; Union[List[str], List[Tuple[str]]]\n</code></pre> <p>Remove stopwords from a list of tokenized texts.</p> <p>Args: tokens : List of tokenized texts, where each item can be a tuple or list of tokens. lang : Language code for stopwords ('english' or 'indonesian'). stopwords : List of additional stopwords to remove, by default None. additional : List of additional stopwords to add, by default None. return_token : Whether to return tokens (True) or joined strings (False), by default True. verbose : Whether to display progress bar, by default False.</p> <p>Returns:</p> <ul> <li> <code>Union[List[str], List[Tuple[str]]]</code>           \u2013            <p>Union[List[str], List[Tuple[str]]]: List of tokenized texts with stopwords removed.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.f_normalize","title":"f_normalize","text":"<pre><code>f_normalize(\n    token: Union[Tuple[str], str],\n    norm_words: dict,\n    return_token: bool = False,\n) -&gt; Union[Tuple[str, ...], str]\n</code></pre> <p>Normalize tokens using a dictionary of normalization mappings.</p> <p>Parameters:</p> <ul> <li> <code>token</code>           \u2013            <p>Token or tuple of tokens to normalize.</p> </li> <li> <code>norm_words</code>           \u2013            <p>Dictionary mapping tokens to their normalized forms.</p> </li> <li> <code>return_token</code>           \u2013            <p>Whether to return tokens (True) or a joined string (False), by default False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Union[Tuple[str, ...], str]</code>           \u2013            <p>Union[Tuple[str, ...], str]: Normalized tokens or joined string of normalized tokens.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.f_lemmatization_en","title":"f_lemmatization_en","text":"<pre><code>f_lemmatization_en(\n    token: Union[Tuple[str], str],\n    return_token: bool = False,\n) -&gt; Union[Tuple[str, ...], str]\n</code></pre> <p>Lemmatize English tokens based on their part-of-speech tags using a lemmatizer.</p> <p>Parameters:</p> <ul> <li> <code>token</code>           \u2013            <p>Token or tuple of tokens to lemmatize.</p> </li> <li> <code>return_token</code>           \u2013            <p>Whether to return tokens (True) or joined string (False), by default False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Union[Tuple[str, ...], str]</code>           \u2013            <p>Union[Tuple[str, ...], str]: If return_token is True, returns a tuple of lemmatized tokens. If return_token is False, returns the lemmatized text as a joined string.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.f_lemmatization_idn","title":"f_lemmatization_idn","text":"<pre><code>f_lemmatization_idn(\n    text: str, return_token: bool = False\n) -&gt; Union[Tuple]\n</code></pre> <p>Lemmatize Indonesian text.</p> <p>Parameters:</p> <ul> <li> <code>text</code>           \u2013            <p>Input text to lemmatize.</p> </li> <li> <code>return_token</code>           \u2013            <p>Whether to return tokens (True) or joined string (False), by default False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Union[Tuple]</code>           \u2013            <p>Union[Tuple[str], str]: If return_token is True, returns a tuple of lemmatized tokens. If return_token is False, returns the lemmatized text as a string.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.lemmatization","title":"lemmatization","text":"<pre><code>lemmatization(\n    data: Union[List[Tuple[str]], List[str]],\n    lang: str,\n    return_token: bool = False,\n    verbose: bool = False,\n)\n</code></pre> <p>Lemmatize tokenized texts based on language.</p> <p>Parameters:</p> <ul> <li> <code>data</code>           \u2013            <p>List of tokenized texts, where each item can be a tuple or list of tokens.</p> </li> <li> <code>lang</code>           \u2013            <p>Language code for lemmatization ('indonesian' or 'english').</p> </li> <li> <code>return_token</code>           \u2013            <p>Whether to return tokens (True) or joined string (False), by default False.</p> </li> <li> <code>verbose</code>           \u2013            <p>Whether to display progress bar, by default False.</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>List[Union[Tuple[str], str]]: List of lemmatized texts. If return_token is True, each item is a tuple of lemmatized tokens. If return_token is False, each item is a joined string of lemmatized tokens.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.f_stemming_en","title":"f_stemming_en","text":"<pre><code>f_stemming_en(\n    text: str, return_token: bool = False\n) -&gt; Union[Tuple[str, ...], str]\n</code></pre> <p>Perform stemming on English text.</p> <p>Parameters:</p> <ul> <li> <code>text</code>           \u2013            <p>Input text to stem.</p> </li> <li> <code>return_token</code>           \u2013            <p>Whether to return tokens (True) or joined string (False), by default False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Union[Tuple[str, ...], str]</code>           \u2013            <p>Union[Tuple[str, ...], str]: If return_token is True, returns a tuple of stemmed tokens. If return_token is False, returns the stemmed text as a joined string.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.f_stemming_idn","title":"f_stemming_idn","text":"<pre><code>f_stemming_idn(\n    text: str, return_token: bool = False\n) -&gt; Union[Tuple[str, ...], str]\n</code></pre> <p>Perform stemming on Indonesian text.</p> <p>Parameters:</p> <ul> <li> <code>text</code>           \u2013            <p>Input text to stem.</p> </li> <li> <code>return_token</code>           \u2013            <p>Whether to return tokens (True) or joined string (False), by default False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Union[Tuple[str, ...], str]</code>           \u2013            <p>Union[Tuple[str, ...], str]: If return_token is True, returns a tuple of stemmed tokens. If return_token is False, returns the stemmed text as a joined string.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.stemming","title":"stemming","text":"<pre><code>stemming(\n    data: List[Tuple[str]],\n    lang: str,\n    return_token: bool = False,\n    verbose: bool = False,\n)\n</code></pre> <p>Perform stemming on tokenized texts based on language.</p> <p>Parameters:</p> <ul> <li> <code>data</code>           \u2013            <p>List of tokenized texts, where each item is a tuple of tokens.</p> </li> <li> <code>lang</code>           \u2013            <p>Language code for stemming ('indonesian' or 'english').</p> </li> <li> <code>return_token</code>           \u2013            <p>Whether to return tokens (True) or joined string (False), by default False.</p> </li> <li> <code>verbose</code>           \u2013            <p>Whether to display a progress bar, by default False.</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>List[str]: List of stemmed texts. If return_token is True, each item is a list of stemmed tokens. If return_token is False, each item is a joined string of stemmed tokens.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.text_manipulation","title":"text_manipulation","text":"<pre><code>text_manipulation(\n    tokens: List[Tuple[str]],\n    lang: str,\n    stopwords: Union[List[str], bool] = False,\n    stem: bool = False,\n    return_dataframe: bool = False,\n    norm_words: Optional[dict] = None,\n    return_token=False,\n    additional: Optional[List[str]] = None,\n    verbose: bool = False,\n)\n</code></pre> <p>Perform text manipulation including normalization, stopword removal, stemming or lemmatization.</p> <p>Parameters:</p> <ul> <li> <code>tokens</code>           \u2013            <p>List of tokenized texts, where each item is a tuple of tokens.</p> </li> <li> <code>lang</code>           \u2013            <p>Language code for text manipulation ('indonesian' or 'english').</p> </li> <li> <code>stopwords</code>           \u2013            <p>List of stopwords or True to use default stopwords for the specified language, by default False.</p> </li> <li> <code>stem</code>           \u2013            <p>Whether to perform stemming (True) or lemmatization (False), by default False.</p> </li> <li> <code>return_dataframe</code>           \u2013            <p>Whether to return results as a DataFrame, by default False.</p> </li> <li> <code>norm_words</code>           \u2013            <p>Dictionary of normalization words, by default None.</p> </li> <li> <code>return_token</code>           \u2013            <p>Whether to return tokens (True) or joined string (False), by default False.</p> </li> <li> <code>additional</code>           \u2013            <p>Additional stopwords to include, by default None.</p> </li> <li> <code>verbose</code>           \u2013            <p>Whether to display progress bars for preprocessing steps, by default False.</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>Union[List[str], pd.DataFrame]: If return_dataframe is False, returns a list of preprocessed texts/tokens. If return_dataframe is True, returns a pandas DataFrame with columns \"raw\" and \"pre\".</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.Tokenizer","title":"Tokenizer","text":"<pre><code>Tokenizer(\n    oov_token: str = None,\n    filters: Optional[str] = string.punctuation,\n    min_count: Optional[int] = None,\n    maxlen: int = 0,\n    padding: Literal[\"pre\", \"post\"] = \"pre\",\n    truncating: Literal[\"pre\", \"post\"] = \"pre\",\n    value: int = 0,\n    dtype=\"int32\",\n)\n</code></pre> <p>A class to tokenize text data, transform it into sequences, and pad sequences.</p> <p>Attributes:</p> <ul> <li> <code>min_count</code>           \u2013            <p>Minimum frequency count for words to be included in the vocabulary.</p> </li> <li> <code>filters</code>           \u2013            <p>Characters to filter out from the text.</p> </li> <li> <code>oov_token</code>           \u2013            <p>Token to use for out-of-vocabulary words.</p> </li> <li> <code>maxlen</code>           \u2013            <p>Maximum length of sequences. If 0, it will be calculated based on the data.</p> </li> <li> <code>padding</code>           \u2013            <p>Padding type (\"pre\" or \"post\").</p> </li> <li> <code>truncating</code>           \u2013            <p>Truncating type (\"pre\" or \"post\").</p> </li> <li> <code>value</code>           \u2013            <p>Value used for padding.</p> </li> <li> <code>dtype</code>           \u2013            <p>Data type of the padded sequences.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>fit</code>             \u2013              <p>Union[List[str], List[Tuple[str]]], y=None) Fits the tokenizer on the given data.</p> </li> <li> <code>encode</code>             \u2013              <p>str) -&gt; list Encodes a single text string into a sequence of integers.</p> </li> <li> <code>decode</code>             \u2013              <p>list) -&gt; str Decodes a sequence of integers back into a text string.</p> </li> <li> <code>texts_to_sequences</code>             \u2013              <p>list) -&gt; list Converts a list of text strings into sequences of integers.</p> </li> <li> <code>sequences_to_texts</code>             \u2013              <p>list) -&gt; list Converts a list of sequences of integers back into text strings.</p> </li> <li> <code>sequences_to_pad</code>             \u2013              <p>list) Pads a list of sequences to the maximum length.</p> </li> <li> <code>texts_to_pad_sequences</code>             \u2013              <p>list) Converts a list of text strings into padded sequences.</p> </li> </ul> Properties <p>word_index : A dictionary mapping words to their integer indices. index_word : A dictionary mapping integer indices to their corresponding words.</p> <p>Parameters:</p> <ul> <li> <code>oov_token</code>           \u2013            <p>Token to use for out-of-vocabulary words (default is None).</p> </li> <li> <code>filters</code>           \u2013            <p>Characters to filter out from the text (default is string.punctuation).</p> </li> <li> <code>min_count</code>           \u2013            <p>Minimum frequency count for words to be included in the vocabulary (default is None).</p> </li> <li> <code>maxlen</code>           \u2013            <p>Maximum length of sequences (default is 0, which means it will be calculated based on the data).</p> </li> <li> <code>padding</code>           \u2013            <p>Padding type (\"pre\" or \"post\", default is \"pre\").</p> </li> <li> <code>truncating</code>           \u2013            <p>Truncating type (\"pre\" or \"post\", default is \"pre\").</p> </li> <li> <code>value</code>           \u2013            <p>Value used for padding (default is 0).</p> </li> <li> <code>dtype</code>           \u2013            <p>Data type of the padded sequences (default is \"int32\").</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.Tokenizer.index_word","title":"index_word  <code>property</code>","text":"<pre><code>index_word\n</code></pre> <p>Returns the index-to-word dictionary.</p> <p>Returns:</p> <ul> <li> <code>dict</code>          \u2013            <p>The index-to-word dictionary.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.Tokenizer.word_index","title":"word_index  <code>property</code>","text":"<pre><code>word_index\n</code></pre> <p>Returns the word-to-index dictionary.</p> <p>Returns:</p> <ul> <li> <code>dict</code>          \u2013            <p>The word-to-index dictionary.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.Tokenizer.decode","title":"decode","text":"<pre><code>decode(token: list) -&gt; str\n</code></pre> <p>Decodes a sequence of integers back into a text string.</p> <p>Parameters:</p> <ul> <li> <code>token</code>           \u2013            <p>The sequence of integers to decode.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code> (              <code>str</code> )          \u2013            <p>The decoded text string.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.Tokenizer.encode","title":"encode","text":"<pre><code>encode(text: str) -&gt; list\n</code></pre> <p>Encodes a single text string into a sequence of integers.</p> <p>Parameters:</p> <ul> <li> <code>text</code>           \u2013            <p>The text string to encode.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code> (              <code>list</code> )          \u2013            <p>The encoded sequence of integers.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.Tokenizer.fit","title":"fit","text":"<pre><code>fit(data: Union[List[str], List[Tuple[str]]], y=None)\n</code></pre> <p>Fits the tokenizer on the given data.</p> <p>Parameters:</p> <ul> <li> <code>data</code>           \u2013            <p>The input data to fit the tokenizer on.</p> </li> <li> <code>y</code>           \u2013            <p>Not used, present for compatibility with sklearn API.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tokenizer</code>          \u2013            <p>The fitted Tokenizer object.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.Tokenizer.sequences_to_pad","title":"sequences_to_pad","text":"<pre><code>sequences_to_pad(sequences: list)\n</code></pre> <p>Pads a list of sequences to the maximum length.</p> <p>Parameters:</p> <ul> <li> <code>sequences</code>           \u2013            <p>The list of sequences to pad.</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>np.ndarray: The padded sequences.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.Tokenizer.sequences_to_texts","title":"sequences_to_texts","text":"<pre><code>sequences_to_texts(sequences: list) -&gt; list\n</code></pre> <p>Converts a list of sequences of integers back into text strings.</p> <p>Parameters:</p> <ul> <li> <code>sequences</code>           \u2013            <p>The list of sequences of integers to convert.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code> (              <code>list</code> )          \u2013            <p>The list of decoded text strings.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.Tokenizer.texts_to_pad_sequences","title":"texts_to_pad_sequences","text":"<pre><code>texts_to_pad_sequences(text: list)\n</code></pre> <p>Converts a list of text strings into padded sequences.</p> <p>Parameters:</p> <ul> <li> <code>text</code>           \u2013            <p>The list of text strings to convert.</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>np.ndarray: The padded sequences.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.Tokenizer.texts_to_sequences","title":"texts_to_sequences","text":"<pre><code>texts_to_sequences(text: list) -&gt; list\n</code></pre> <p>Converts a list of text strings into sequences of integers.</p> <p>Parameters:</p> <ul> <li> <code>text</code>           \u2013            <p>The list of text strings to convert.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code> (              <code>list</code> )          \u2013            <p>The list of sequences of integers.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.Tokenizer.transform","title":"transform","text":"<pre><code>transform(data)\n</code></pre> <p>Transforms the given data into padded sequences.</p> <p>Parameters:</p> <ul> <li> <code>data</code>           \u2013            <p>The input data to transform.</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>np.ndarray: The transformed and padded sequences.</p> </li> </ul>"},{"location":"utils/text_preprocessing/#optialgo.count_words","title":"count_words","text":"<pre><code>count_words(\n    data: Union[List[str], List[Tuple[str]]],\n    min_count: Optional[int] = None,\n    return_dataframe: bool = False,\n)\n</code></pre> <p>Count the occurrences of words in a list of tokenized texts or strings.</p> <p>Parameters:</p> <ul> <li> <code>data</code>           \u2013            <p>List of tokenized texts (list of tuples or list of strings).</p> </li> <li> <code>min_count</code>           \u2013            <p>Minimum count threshold for words to be included in the result, by default None.</p> </li> <li> <code>return_dataframe</code>           \u2013            <p>Whether to return the result as a pandas DataFrame, by default False.</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>Union[dict, pd.DataFrame]: If return_dataframe is False, returns a dictionary where keys are words and values are counts. If return_dataframe is True, returns a DataFrame with columns \"words\" and \"counts\".</p> </li> </ul>"}]}